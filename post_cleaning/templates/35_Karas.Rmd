---
title: "Penalized regression inference regarding variable selection in regular and high dimensions: comparison of selected methods implemented in R"
author:
 - name: "Marta Karas"
   affiliation: [1]
   email: "marta.karass@gmail.com"
   contact: yes
affiliation:
 - "Department of Biostatistics, Indiana University Fairbanks School of Public Health"
keywords: "penalized regression; inference; p-value"
packages: "lassoscore; hdi; refund"
# bibliography: bibliography.bib
output:  
        erum::erum_abstract:
                  keep_tex: TRUE
---

In recent years, penalized regression techniques, such as lasso, have
become commonly used for variable selection in linear regression
modeling, but relatively little work has been done on quantifying the
uncertainty in these procedures. Here, we perform comparison of four
different approaches to this problem. With a score test method,
penalized regression of an outcome on all but a single feature is
performed, and test for correlation of the residuals with the held-out
feature follows. PEER Ridge estimation procedure exploits the
equivalence between penalized least squares estimation and a linear
mixed model representation, and thus provides an automatic selection of
tuning parameter alpha using REML criterion; then, the General SVD
provides algebraic insight and a convenient way to derive the variance
expressions of the estimates, which allows to perform inference
regarding variable selection. With Multi sample-splitting method, the sample is split into two equal halves, where the first half
is used for variable selection and the second half, with the reduced set
of already pre-selected variables, is used for statistical inference in
terms of $p$-values. In stability selection method, a stable
subset of variables is selected in stochastic simulation where
probability of a variable being selected into a model is approximated.
We utilized **R** implementations of the methods listed above to compare
variables selection inference in terms of FDR and power. We experimented
with different covariance settings as well as dimensions of X design
matrix in looking for situations when one method might be preferred.

<!--  -->
<!-- **References** -->
<!-- [1]: Voorman, A., Shojaie, A., Witten, D. Inference in High Dimensions with the Penalized Score Test (2014). arXiv:1401.2678 [stat.ME] 
 [2]: Randolph, T. W., Harezlak, J., Feng, Z. Structured penalties for functional linear models - partially empirical eigenvectors for regression (2012). Electronic Journal of Statistics, 6, 323-353. 
 [3]: Dezeure, R., Buhlmann, P., Meier, L., Meinshausen, N. High-Dimensional Inference: Confidence Intervals, p-Values and R-Software hdi (2015). Statistical Science, 30(4), 533-558. -->
